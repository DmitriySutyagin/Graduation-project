## **2.3.	Создание и обучение глубокой нейронной сети для распознавания опухоли молочной железы.**

Для создания глубокой нейронной сети необходимо создать новое виртуальное окружение на интегрированной среде разработке Anaconda. 
Для этого необходимо в терминале IDE Anaconda выполнить команду, показанную на рисунке 2.3:  
![Screenshot](../main/Screenshot/Conda%20create%20-%20n%20venv.png)  
Рисунок 2.3 - Создание виртуального окружения  
Далее активировать среду, выполнив следующую команду, показанную на рисунке 2.4:  
![Screenshot](../main/Screenshot/активация%20среды%20conda.png)  
Рисунок 2.4 – Активация среды
В открывшемся проекте необходимо импортировать необходимые библиотеки (рисунок 2.4) и модули для дальнейшей разработки и обучения нейронной сети. Приведу их название и краткую характеристику:
* Библиотека «NumPy» – это библиотека для работы с многомерными массивами и матричными операциями, входит как расширение языка программирования Python
* Модуль «OS» – это модуль для работы с операционной системой, служит проводником к наборам данных
* Модуль «Random» – данная функция необходима для генерации случайных чисел
* Библиотека «PIL» – это библиотека для работы с изображениями
* Библиотека «Keras» была отмечена в параграфе 2.1
* Matplotlib — библиотека на языке программирования Python для визуализации данных двумерной графикой  
* Модуль «SkLearn.utils» (Scikit-learn) – это модуль для различных утилит машинного обучения, в данном случае он используется для перемешивания данных.  
![Screenshot](../main/Screenshot/import%20libr.png?raw=true)   
Рисунок 2.5 – Импортирование библиотек  
Первым шагом к обучению нашей модели нейронной сети будет указание пути к набору данных Breast Histopathology Images и создание пустых массивов, 
в которых будут храниться данные обучающей и тестовой выборки – изображения и их метки соответственно (рисунок 2.6).  
![Screenshot](../main/Screenshot/Пустые%20масивы.png)  
Рисунок 2.6 – Загрузка данных для обучения и пустые массивы данных  
Далее необходимо сделать инициализацию папок внутри набора данных Dataset содержащий изображения сегментированных снимков компьютерной томографии опухоли молочной железы,
а также с помощью библиотеки OpenCV загружаем изображение в серых оттенках и обрезаем размер изображения до входного параметра нейронной сети, 
далее данные загружаются в два массива индексируются (рисунок 2.7) и выводится на экран, результат проиллюстрирован на рисунке 2.8.
![Sxreenshot](../main/Screenshot/индексация%20изображений.png?raw=true)  
Рисунок 2.7 – Индексация изображений
![Screenshot](../main/Screenshot/инднемация%20изображений.png)  
Рисунок 2.8 -  
Далее следует разделение дынных на тренировочные и тестовые массивы данных, а также разделение тренировочной выборки на тренировочную и валидационную выборку.
Тренировочная выборка используется для обучения модели, валидационная – применяется для оценки переобучения модели, оценки ошибки прогнозирования при выборе модели,
 настройки гиперпараметров и выбора лучшей модели, а также она показывает, как может повести себя модель с новыми данными. Тестовая выборка используется для оценки работы готовой модели,
 оценки ошибки обобщения для окончательной выбранной модели.  
Далее выборки преобразуются в бинарную матрицу, с помощью функции «keras.utils.to_categorical()», и происходит нормализация тренировочных данных путем деления на 255,
 так как нейронные сети не могут обрабатывать входные данные с большим весом, это может привести к нарушению процесса обучения и необходимо приводить значения пикселей изображения от 0 до 1 (рисунок 2.9).  
![Screenshot](../main/Screenshot/Категоризация%20и%20разделение%20выборок%20(1).png)  
 
Рисунок 2.9 – Нормализация и разделение выборок  
Теперь приступим к созданию архитектуры модели, для этого необходимо сделать описание архитектуры модели с помощью библиотеки «Keras», где определяется последовательная модель сети («Sequential»), в которой последовательно добавляются слои обработки данных и далее с помощью «KerasTuner» подбираем гиперпараметры.  
«KerasTuner» - это простой в использовании масштабируемый фреймворк гиперпараметрической оптимизации, который решает проблемы гиперпараметрического поиска. «KerasTuner» поставляется со встроенными алгоритмами байесовской оптимизации, гиперполосности и случайного поиска, а также разработан таким образом, чтобы исследователи могли легко расширять его для экспериментов с новыми алгоритмами поиска (см. рисунок 2.10).  
![Screen](../main/Screenshot/архитектура%20модели.png)  

Рисунок 2.10 – Архитектура модели  
Архитектура модели содержит слои «Conv2D», которые являются сверточными слоями, каждый из них содержит 16, 32, 64, 128, 256, 512 нейрона, а также размеры ядер свертки 5 на 5 и  3 на 3 пикселя, с активационными функциями: «ReLU», «SeLU», «eLU», «Softmax» и параметром «padding='same'», что означает «одинаковое заполнение». Без заполнения размерность выходного изображения после свертки будет меньше, чем у входного. В результате использования параметра заполнения «padding='same'» размерность выходного изображения сохраняется, что упрощает дальнейшую обработку.  
ReLU (Rectified Linear Unit) – это одна из самых популярных активационных функций в нейронных сетях. Она применяется к выходным значениям каждого нейрона, чтобы добавить нелинейность и увеличить способность модели обучаться более сложным функциям.
Функция ReLU имеет очень простой вид:  

![Screenshot](../main/Screenshot/relu.png)

где, x – входное значение нейрона.  
Если значение x положительное, то активация будет передана без изменений. Если же значение x отрицательное, то активация будет обнулена (выход активации равен 0).
Преимущества использования функции ReLU заключаются в ее простоте, высокой скорости вычисления и способности предотвращать затухание градиента при обратном распространении ошибки.
Кроме того, эта функция может помочь сети обучаться разреженным представлениям данных, что может быть полезно при работе с большими наборами данных.  
SELU (масштабированная экспоненциальная линейная единица) — это функция активации, которая включает нормализацию, основанную на центральной предельной теореме.  
Функция выглядит как:  
ϕ(v i ) = U(v i )  
где U — ступенчатая функция Хевисайда.  
Основное преимущество SELU заключается в том, что проблема исчезающего и взрывающегося градиента невозможна. Однако эта функция требует дополнительного тестирования перед использованием.  
ELU (Exponential Linear Unit) - это функция активации, которая представляет собой измененную версию ReLU (Rectified Linear Unit), которая помогает ускорить обучение глубоких нейронных сетей и справляется с проблемой "мертвых нейронов".  
Функция ELU выглядит следующим образом:  
![Screenshot](../main/Screenshot/elu.png)   
где a – это гиперпараметр, который контролирует значение насыщения для отрицательных входов.  
Параметр a в ELU позволяет адаптировать функцию активации к конкретным требованиям задачи, что может быть полезно в различных приложениях. 
ELU является более гладкой функцией, особенно вокруг нуля, что может способствовать более стабильному обучению.  
Функция активации Softmax широко используется в нейронных сетях, особенно в контексте задач многоклассовой классификации. 
Она преобразует вектор вещественных чисел (логиты, полученные из предыдущего слоя нейронной сети) в вероятностное распределение.  
Далее следует слой «MaxPooling2D», который выполняет подвыборку изображения и уменьшает его размеры в два раза. Это позволяет сократить количество параметров для обработки и делает модель более легковесной. В каждом таком слое также присутствует слой «Dropout», который предотвращает переобучение модели. Метод «Dropout(0.25)» означает, что 25% случайно выбранных нейронов будут игнорироваться на каждой обучающей эпохе. Рассмотрим данный метод поподробнее.  
«Dropout» – это метод регуляризации для искусственных нейронных сетей, который заключается в случайном «выключении» определенного числа нейронов во время обучения. В процессе обучения каждый нейрон имеет вероятность p быть удаленным (отключенным) сетью. Это означает, что входные данные не будут передаваться через этот нейрон, и его связи с другими нейронами не будут участвовать во время этой конкретной итерации обучения. Таким образом, «Dropout» может предотвратить переобучение сети и улучшить ее обобщающую способность.  
Формула метода «Dropout» выглядит следующим образом:  
![Screenshot](../main/Screenshot/dropout.png?raw=true)  
где, x_i – входные данные,  
p – вероятность удаления элементов,  
r_i – случайная бинарная маска, которая принимает значения 0 или 1 с вероятностью p и (1-p) соответственно.  
Далее следует слой «Flatten», который выполняет преобразование двумерного массива данных в одномерный. Затем добавляются три слоя полносвязных многослойных перцептрона («Dense»), каждый из которых содержит набор нейронов. Нейроны в этих слоях активируются функцией «ReLU».  
Последний слой перцептрона содержит количество нейронов, равное количеству классов и использует активационную функцию «softmax», функция «softmax» помогает получить вероятности для каждого класса, а значение на выходе этого слоя является вероятностью принадлежности объекта к каждому из классов.  
Также стоит рассмотреть операцию «Flatten» более подробно. Flatten – это операция в нейронных сетях, которая преобразует многомерный тензор в одномерный тензор путем «расплющивания» всех измерений изображения.  
Функция «softmax» – это нелинейная активационная функция, которая обычно используется в многослойных нейронных сетях для преобразования выходных значений каждого нейрона в вероятности отнесения входного сигнала к различным классам.  
Функция «softmax» определяется следующей формулой:  
![Sreenshot](../main/Screenshot/softmax.png)  
где, z – это вектор значений линейной комбинации входных данных и параметров модели (без акткивации),  
а j – номер элемента вектора, соответствующий конкретному классу.  
Эта функция берет на вход вектор z, который может быть любой длины, и преобразует его в новый вектор σ(z) можно рассматривать как вероятность того, что взодной сигнал относится к соответствующему классу.  
Таким образом, модель обучается на входных изображениях, после чего может проводить классификацию новых изображений на соответствующие классы.
В данной работе для глубокого обучения нейронной сети были использованы три следующих оптимизатора:  

* Adam — один из самых эффективных алгоритмов оптимизации в обучении нейронных сетей. Он сочетает в себе идеи RMSProp и оптимизатора импульса. Вместо того чтобы адаптировать скорость обучения параметров на основе среднего первого момента (среднего значения), как в RMSProp, Adam также использует среднее значение вторых моментов градиентов. В частности, алгоритм вычисляет экспоненциальное скользящее среднее градиента и квадратичный градиент, а параметры beta1 и beta2 управляют скоростью затухания этих скользящих средних.   
	Гиперпараметры:  
	* значение β1(beta1) почти 0,9  
	* β2 (бета2) — почти 0.999  
	* ε — предотвращение деления на ноль (10^-8) (не слишком сильно влияет на обучение)
   
	Его преимущества:  
 	* Простая реализация.  
  	* Вычислительная эффективность.  
  	* Небольшие требования к памяти.  
	* Инвариант к диагональному масштабированию градиентов.  
	* Хорошо подходит для больших с точки зрения данных и параметров задач.  
	* Подходит для нестационарных целей.  
	* Подходит для задач с очень шумными или разреженными градиентами.    
	* Гиперпараметры имеют наглядную интерпретацию и обычно требуют небольшой настройки.  
  
* Среднеквадратичное распространение корня (RMSprop) — это экспоненциально затухающее среднее значение наблюдается на рисунке 2.11.
  
Существенным свойством RMSprop является то, что мы не ограничены только суммой прошлых градиентов, но более ограничены градиентами последних временных шагов. RMSprop вносит свой вклад в экспоненциально затухающее среднее значение прошлых «квадратичных градиентов». В RMSProp мы пытаемся уменьшить вертикальное движение, используя среднее значение, потому что они суммируются приблизительно до 0, принимая среднее значение. RMSprop предоставляет среднее значение для обновления.  
![Screenshot](../main/Screenshot/RMSprop.png)   
Рисунок 2.11 - Среднеквадратичное распространение корня (RMSprop)

* SGD – это вариант градиентного спуска, при котором обновление параметров происходит после вычисления градиента на основе одного обучающего примера или небольшого пакета (batch) примеров. Это делает процесс быстрее и менее ресурсоёмким по сравнению со стандартным градиентным спуском.  
Формула SGD на рисунке 2.12:  
![Screenshot](../main/Screenshot/SGD.png)  
Рисунок 2.12 - Формула  SGD  
В случае SGD, формула обновления параметров остаётся той же, но градиент ∇θJ(θ) вычисляется на основе одного случайно выбранного обучающего примера или пакета примеров, а не всего набора данных.
SGD широко используется в обучении различных видов нейронных сетей, включая свёрточные нейронные сети (CNN), рекуррентные нейронные сети (RNN) и многослойные перцептроны (MLP).
Он особенно полезен, когда работает с очень большими наборами данных, так как в таких условиях полный градиентный спуск может быть слишком затратным по времени и памяти. 
«SGD» позволяет модели быстро обновляться и адаптироваться, используя только небольшой подвыбор данных на каждом шаге обновления.

Далее нам необходимо выбрать функцию потерь (основанную на «binary_crossentropy» – бинарная кросс-энтропии). Данная кросс-энтропийя вычисляет потери между истинными и прогнозируемыми метками.
Эту кросс-энтропийную используют при потери для двоичных (0 или 1) приложений классификации. Для функции потерь требуются следующие входные данные:    
* «y_true» (метка true): это либо 0, либо 1.  
* «y_pred» (прогнозируемое значение): Это прогноз модели, т. е. единственное значение с плавающей запятой, которое представляет собой либо логит, (т. е. Значение в [-inf, inf], когда «from_logits=False»), либо вероятность (т. е. Значение в [0., 1.], когда «from_logits=False»).

В процессе обучения нейронной сети для оценки качества моделей и сравнения различных алгоритмов использовалась метрика «AUC-ROC».  
Кривая «AUC-ROC», или Область под кривой характеристики рабочего приемника, представляет собой графическое представление производительности модели бинарной классификации при различных пороговых значениях классификации. Обычно, используется в машинном обучении для оценки способностей моделей, различающихся двумя классами, обычно положительным классом (например, наличие заболевания) и отрицательным классом (например, отсутствие заболевания).  
 AUC представляет собой площадь под кривой «ROC». Он измеряет общую производительность модели бинарной классификации. Поскольку и «TPR», и FPR варьируются от 0 до 1, площадь всегда будет находиться в диапазоне от 0 до 1, а большее значение «AUC» означает лучшую производительность модели.
Наша главная цель — максимизировать эту область,
 чтобы иметь самый высокий «TPR» и самый низкий «FPR» при заданном пороге. «AUC» измеряет вероятность того, что модель присвоит случайно выбранному положительному экземпляру более высокую прогнозируемую вероятность по сравнению со случайно выбранным отрицательным экземпляром.  
Наша нейронная сеть настраивается с помощью метода «compile» — этот метод входит в «TensorFlow», который настраивает модель для обучения.  
Он устанавливает аргументы, которые вы ему передаете: оптимизатор, функцию потерь, показатели, ускоренное выполнение.  
Вы можете запускать его несколько раз, он просто перезапишет настройки, которые вы установили ранее.  
В машинном обучении и статистике задается коэффициент скорости обучения («learning rate») — настраиваемый параметр алгоритма оптимизации, который определяет размер шага на каждой итерации, 
при движении к минимуму функции потерь.  Поскольку он влияет на то, в какой степени вновь полученная информация превосходит старую, он метафорически представляет скорость,
с которой модель машинного обучения «обучается».  
Далее с помощью метода Байесовской оптимизации инструмента фреймворка kerus_tuner будет осуществлен подбор лучших гиперпараметров для обучения модели, применение данного метода показано на рисунке 2.13.  
![Screenshot](../main/Screenshot/бАУСОВСКАЯ%20ОПТИМИЗАЦЯ%20.png)  
Рисунок 2.13 - Метод Байесовской оптимизации  
Байесовская оптимизация — это итерационный метод, позволяющий оценить оптимум функции, не дифференцируя её. Кроме того, на каждой итерации метод указывает, в какой следующей точке мы с наибольшей вероятностью улучшим нашу текущую оценку оптимума. Это позволяет значительно сократить количество вычислений функции, каждое из которых может быть довольно затратным по времени.  
Байесовская оптимизация имеет два основных компонента:  
* вероятностную модель, которая приближает распределение значений целевой функции в зависимости от имеющихся исторических данных (часто в качестве такой модели выбирают гауссовские процессы)  
* функцию, которая позволяет по некоторым статистикам текущей вероятностной модели функции 𝑓 указать, в какой следующей точке нужно вычислить значение 𝑓. Эта функция называется acquisition function.
Она должна балансировать между exploration и exploitation в следующем смысле:  
* exploration — исследовать те точки, в которых дисперсия нашей вероятностной модели велика  
* exploitation — исследовать те точки, где среднее нашей модели велико (и может служить оценкой максимума 𝑓)  
В результате работы фреймворка «KerasTuner» было подобрано 10 сводок настройки гиперпараметров (см. рисунок 2.14) для обучения модели и результаты метрики для каждого испытания. На основании этих испытаний выбирается модель с наилучшими результатами, по которой в дальнейшем будет выполняться прогноз заболевания рака молочной железы (см. рисунок 2.15).  


